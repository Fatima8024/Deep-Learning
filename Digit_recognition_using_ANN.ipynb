{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEzpakC2GIcs3wNMbkErwb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatima8024/Deep-Learning/blob/main/Digit_recognition_using_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP5qYmg3mKV8",
        "outputId": "f4f76ea8-571b-4b6b-defb-591951482bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.4759 - val_accuracy: 0.9567 - val_loss: 0.1440\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.1173 - val_accuracy: 0.9681 - val_loss: 0.1056\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0768 - val_accuracy: 0.9727 - val_loss: 0.0943\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0573 - val_accuracy: 0.9742 - val_loss: 0.0839\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0418 - val_accuracy: 0.9726 - val_loss: 0.0937\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "   No of Layers Neurons in Layers Output Layer Activation Function  \\\n",
            "0             3           128, 64                          softmax   \n",
            "\n",
            "   Data Split Size  Accuracy  Loss Value  Precision  \n",
            "0              0.2    0.9741     0.08909    0.97416  \n"
          ]
        }
      ],
      "source": [
        "# prompt: Digit recognition using an artificial neural network: Create a system to identify digits and populate the table. Use the mnist dataset for the experiment and Python code TensorFlow and Keras. show output in a table of 4 rows which includes no of layers, neurons in layers, output layer activation function, data split size, accuracy, loss value and precision and generate an excel sheet\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Data Splitting\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 784-dimensional vector\n",
        "  Dense(128, activation='relu'),   # First hidden layer with 128 neurons and ReLU activation\n",
        "  Dense(64, activation='relu'),    # Second hidden layer with 64 neurons and ReLU activation\n",
        "  Dense(10, activation='softmax') # Output layer with 10 neurons (for 10 digits) and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "precision = precision_score(y_test, y_pred_classes, average='macro')\n",
        "\n",
        "# Results Table (DataFrame)\n",
        "results = pd.DataFrame({\n",
        "    'No of Layers': [3],  # Number of hidden layers + output layer\n",
        "    'Neurons in Layers': ['128, 64',],  # Number of neurons in each hidden layer\n",
        "    'Output Layer Activation Function': ['softmax'],\n",
        "    'Data Split Size': [0.2],  # Test size\n",
        "    'Accuracy': [accuracy],\n",
        "    'Loss Value': [loss],\n",
        "    'Precision': [precision]\n",
        "})\n",
        "\n",
        "# Print the Results Table\n",
        "print(results)\n",
        "\n",
        "\n",
        "# Save to Excel\n",
        "results.to_excel('digit_recognition_results.xlsx', index=False)"
      ]
    }
  ]
}